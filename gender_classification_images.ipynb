{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2ffa879",
   "metadata": {},
   "source": [
    "# Image Analysis\n",
    "\n",
    "Note: some code in this notebook is taken or derived from the manual provided for the university course \"data mining\" at UU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6cb3a0",
   "metadata": {},
   "source": [
    "## Motivation of the query and method\n",
    "\n",
    "In recent years, more LGBTQ people are represented in film and television. For example, a recent report suggests that about 4.5 percent of the US population identifies as LGBTQ and 6.7 percent of recurring TV characters are LGBTQ (Dawson, 2020). This makes me wonder whether LGBTQ people are represented accordingly in (Google) images. \n",
    "As its impossible to identify LGBTQ people based on an image, I focus on same-sex couples.\n",
    "\n",
    "With the Google Images query \"couple\" I want to investigate if same-sex couples are adequately represented in images.\n",
    "\n",
    "The focus on same-sex couples is also based on the method I work with, gender classification, specifically classifying the gender of a face. Most images that are shown based on this query include faces, which makes this an appropriate method for investigation. With being able to classify the faces of an image as male or female, I can see if an image portrays a same-sex couple or a couple of the opposite gender. This of course only works if there are faces in an image, additionally, a face might not be recognized if only the profile is shown (e.g., when two people are kissing each other, or looking at each other).\n",
    "\n",
    "Analyzing the images of this query uncovers whether the \"standard\"/typical image of a couple is one including a woman and a man, or if same-sex couples (so either two men or two women) are also represented when searching for images of couples.\n",
    "\n",
    "Based on a first look at the pictures that come up with this query, I expect same-sex couples to be underrepresented in the images.\n",
    "\n",
    "Dawson, L. (2020, December 15). Presence vs. representation: Report breaks down LGBTQ visibility on TV. NBCNews.com. Retrieved January 16, 2022, from https://www.nbcnews.com/feature/nbc-out/presence-vs-representation-report-breaks-down-lgbtq-visibility-tv-n1251153 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4e5c90",
   "metadata": {},
   "source": [
    "Ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f87457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e3a249",
   "metadata": {},
   "source": [
    "Installing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ce39ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install simple_image_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "455c8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_image_download import simple_image_download as simp\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1a18f5",
   "metadata": {},
   "source": [
    "Downloading images\n",
    "\n",
    "I used code from this page for downloading the images from google: https://github.com/RiddlerQ/simple_image_download/blob/master/Example/Test1.py\n",
    "I downloaded 500 images because I need to filter images including 2 faces, so I need a sufficient amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "805a0aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[=========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "response = simp.simple_image_download\n",
    "\n",
    "response().download('couple', 500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35924dbb",
   "metadata": {},
   "source": [
    "Get the name of every saved picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15d15fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = '/Users/arleenlindenmeyer/Desktop/ADS/data_mining/exam2/simple_images/couple/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a24582ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a949ebe6",
   "metadata": {},
   "source": [
    "Get the path of every saved picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67405144",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = []\n",
    "\n",
    "for i in images:\n",
    "    path_img = '/Users/arleenlindenmeyer/Desktop/ADS/data_mining/exam2/simple_images/couple/'+i\n",
    "    path.append(path_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36056137",
   "metadata": {},
   "source": [
    "Create dataframe with name and path of every saved image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ac27ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['image'] = images\n",
    "df['path'] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad4ece2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>couple_73.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>couple_228.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>couple_382.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>couple_101.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>couple_414.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image                                               path\n",
       "0   couple_73.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...\n",
       "1  couple_228.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...\n",
       "2  couple_382.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...\n",
       "3  couple_101.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...\n",
       "4  couple_414.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63c2fcd",
   "metadata": {},
   "source": [
    "Load face classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3260971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00bc0c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classification = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23e969d",
   "metadata": {},
   "source": [
    "Load gender classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a70289c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-16 23:13:16.998345: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "#!wget https://github.com/oarriaga/face_classification/raw/master/trained_models/gender_models/gender_mini_XCEPTION.21-0.95.hdf5\n",
    "\n",
    "gender_classifier = load_model('gender_mini_XCEPTION.21-0.95.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc60f749",
   "metadata": {},
   "source": [
    "Function to get the faces of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec96556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_offsets(face_coordinates, offsets):\n",
    "    \"\"\"\n",
    "    Derived from https://github.com/oarriaga/face_classification/blob/\n",
    "    b861d21b0e76ca5514cdeb5b56a689b7318584f4/src/utils/inference.py#L21\n",
    "    \"\"\"\n",
    "    x, y, width, height = face_coordinates\n",
    "    x_off, y_off = offsets\n",
    "    return (x - x_off, x + width + x_off, y - y_off, y + height + y_off)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39e3810",
   "metadata": {},
   "source": [
    "Function to load the images from a path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fa0d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_path(image_path, target_size=None, color_mode='rgb'):\n",
    "    pil_image = image.load_img(image_path, \n",
    "                               target_size=target_size,\n",
    "                            color_mode=color_mode)\n",
    "    return image.img_to_array(pil_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6626b247",
   "metadata": {},
   "source": [
    "In a loop, I load each image in the dataframe, identify and get the faces, and classify each face. In the end, I have lists containing the number of faces in each image, if the image contains a woman/women and if the image contains a man/men."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b2a1a",
   "metadata": {},
   "source": [
    "Note: I changed settings of the face classifier because with the setting we used in the tutorial a lot of faces were missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41db96cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166957f62a7f475f98eed8cc5d75dbce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "woman_yes = []\n",
    "man_yes = []\n",
    "\n",
    "labels = ['woman', 'man'] #labels for gender classifier\n",
    "\n",
    "n_faces = [] \n",
    "\n",
    "for file in tqdm(df.path): # loop over images\n",
    "    \n",
    "    pre_image = load_image_from_path(file, color_mode='grayscale') #loading the images\n",
    "    gray_image = np.squeeze(pre_image).astype('uint8')\n",
    "    \n",
    "    faces = face_classification.detectMultiScale(gray_image, 1.2, 4) # detect the faces\n",
    "    \n",
    "    GENDER_OFFSETS = (10, 10)\n",
    "    INPUT_SHAPE_GENDER = gender_classifier.input_shape[1:3]\n",
    "\n",
    "    genders = [] #list containing \"man\" or \"woman\" for each man/woman in the picture\n",
    "\n",
    "    for face_coordinates in faces: # using the output of the face classifier\n",
    "        x1, x2, y1, y2 = apply_offsets(face_coordinates, GENDER_OFFSETS) # extends the bounding box\n",
    "        face_img = gray_image[y1:y2, x1:x2] # only get the face \n",
    "        face_img = cv2.resize(face_img, (INPUT_SHAPE_GENDER)) # resize the image\n",
    "        face_img = face_img.astype('float32') / 255.0 # preprocess the image\n",
    "        face_img = np.expand_dims(face_img, 0) # batch of one\n",
    "        probas = gender_classifier.predict(face_img) #classify the gender of the face\n",
    "\n",
    "        genders.append(labels[np.argmax(probas[0])]) #appends \"man\" or \"woman\" depending on the gender classifier\n",
    "        \n",
    "        \n",
    "\n",
    "    if 'man' in genders: #appends 1 to list \"man\" if there is one man or more in the picture\n",
    "        man = 1\n",
    "    else: \n",
    "        man = 0\n",
    "\n",
    "    if 'woman' in genders: #appends 1 to list \"woman\" if there is one woman or more in the picture\n",
    "        woman = 1\n",
    "    else: \n",
    "        woman = 0\n",
    "\n",
    "    n_faces.append(len(faces)) # append to list for number of faces\n",
    "    woman_yes.append(woman) # append to list for if there is one woman or more present in the image\n",
    "    man_yes.append(man) # append to list for if there is one man or more present in the image\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078172b",
   "metadata": {},
   "source": [
    "Adding the lists as columns to the dataframe of the images. For the columns woman and man i did not differentiate if there is one or more woman/man in the image, as I am only going to look at couples of 2 people/faces and I can determine from just the indication if men or women are present if the couple is same-sex or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "035fc1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_faces'] = n_faces\n",
    "df['woman'] = woman_yes\n",
    "df['man'] = man_yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "803967fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>path</th>\n",
       "      <th>n_faces</th>\n",
       "      <th>woman</th>\n",
       "      <th>man</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>couple_73.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>couple_228.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>couple_382.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>couple_101.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>couple_414.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image                                               path  \\\n",
       "0   couple_73.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "1  couple_228.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "2  couple_382.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "3  couple_101.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "4  couple_414.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "\n",
       "   n_faces  woman  man  \n",
       "0        0      0    0  \n",
       "1        0      0    0  \n",
       "2        0      0    0  \n",
       "3        0      0    0  \n",
       "4        0      0    0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224f231c",
   "metadata": {},
   "source": [
    "Not all images include faces, and the face classifier does not recognize every face in an image (or recognizes a faces when there is none, but this occurs more rarely). To fix this issue and to be able to investigate my question, I select only images in the dataframe in which two faces are recognized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0afeff62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>path</th>\n",
       "      <th>n_faces</th>\n",
       "      <th>woman</th>\n",
       "      <th>man</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>couple_455.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>couple_394.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>couple_402.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>couple_479.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>couple_438.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image                                               path  \\\n",
       "11  couple_455.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "13  couple_394.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "15  couple_402.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "21  couple_479.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "30  couple_438.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "\n",
       "    n_faces  woman  man  \n",
       "11        2      1    1  \n",
       "13        2      1    1  \n",
       "15        2      1    1  \n",
       "21        2      1    1  \n",
       "30        2      1    1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_couple = df[df['n_faces'] == 2]\n",
    "df_couple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aeadec",
   "metadata": {},
   "source": [
    "In 94 of the images, the face classifier detects 2 faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc6cab5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_couple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a63203",
   "metadata": {},
   "source": [
    "Out of these 94 images, 58 are classified as couples of the opposite sex (61.7%), and 36 are classified as couples of the same sex (38.3%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95e7f8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_sex = df_couple[(df_couple.woman == 1) & (df_couple.man == 1) ]\n",
    "len(diff_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c98e64b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>path</th>\n",
       "      <th>n_faces</th>\n",
       "      <th>woman</th>\n",
       "      <th>man</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>couple_455.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>couple_394.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>couple_402.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>couple_479.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>couple_438.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image                                               path  \\\n",
       "11  couple_455.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "13  couple_394.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "15  couple_402.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "21  couple_479.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "30  couple_438.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "\n",
       "    n_faces  woman  man  \n",
       "11        2      1    1  \n",
       "13        2      1    1  \n",
       "15        2      1    1  \n",
       "21        2      1    1  \n",
       "30        2      1    1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_sex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0deed866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_sex = df_couple[(df_couple.woman == 0) | (df_couple.man == 0) ]\n",
    "len(same_sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894d0e5",
   "metadata": {},
   "source": [
    "Most images of same sex couples show 2 male faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4876db29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_sex_women = df_couple[(df_couple.woman == 1) & (df_couple.man == 0) ]\n",
    "len(same_sex_women)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c23eb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>path</th>\n",
       "      <th>n_faces</th>\n",
       "      <th>woman</th>\n",
       "      <th>man</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>couple_45.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>couple_199.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>couple_205.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>couple_430.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>couple_353.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image                                               path  \\\n",
       "58    couple_45.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "63   couple_199.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "99   couple_205.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "266  couple_430.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "295  couple_353.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "\n",
       "     n_faces  woman  man  \n",
       "58         2      1    0  \n",
       "63         2      1    0  \n",
       "99         2      1    0  \n",
       "266        2      1    0  \n",
       "295        2      1    0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_sex_women.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f32db0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_sex_men = df_couple[(df_couple.woman == 0) & (df_couple.man == 1) ]\n",
    "len(same_sex_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfb1d8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>path</th>\n",
       "      <th>n_faces</th>\n",
       "      <th>woman</th>\n",
       "      <th>man</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>couple_52.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>couple_360.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>couple_287.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>couple_297.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>couple_133.jpeg</td>\n",
       "      <td>/Users/arleenlindenmeyer/Desktop/ADS/data_mini...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image                                               path  \\\n",
       "68    couple_52.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "91   couple_360.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "119  couple_287.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "227  couple_297.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "268  couple_133.jpeg  /Users/arleenlindenmeyer/Desktop/ADS/data_mini...   \n",
       "\n",
       "     n_faces  woman  man  \n",
       "68         2      0    1  \n",
       "91         2      0    1  \n",
       "119        2      0    1  \n",
       "227        2      0    1  \n",
       "268        2      0    1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_sex_men.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6180a740",
   "metadata": {},
   "source": [
    "## Conclusion and discussion \n",
    "\n",
    "The results show that about 38% of the images in which 2 faces were recognized are same-sex couples, and 2/3 of these are classified as male same-sex couples, 1/3 as female same-sex couples. In this case, same-sex couples would even be overrepresented, and my hypothesis would be incorrect.\n",
    "\n",
    "However, looking at samples of couples of opposite sex and same sex, there were a lot of mistakes in the classifications (I looked at the images shown in the head of the dataframes for diff_sex, same_sex_women and same_sex_men). 1 of the 5 sample images for couples of the opposite sex showed 2 female faces and was therefore misclassified. All of the sample images for same-sex female couples were misclassified and were acutally showing couples of opposite sex. Only 1 out of the 5 sample images for same-sex male couples was correctly classified, the 4 others were actually showing couples of opposite sex.\n",
    "\n",
    "Because of the flaws of both the face classifier (as many faces are missed) and gender classifier (misgendering faces), it is hard to draw any conclusion and answer the hypothesis based on these results. Further, some images only include hands or the back of people, thus cannot be analyzed with a face classifier. I must note that in the sample images also faces shown from the side and even the back of the head were identified as faces, but these were often misclassified by the gender classifier.\n",
    "\n",
    "It would be interesting to be able to classify gender based on other parts as well (so, e.g., hands or a back shot of people) to be able to include these in the analysis. \n",
    "Additionally, I think it would be interesting to investigate skin color, to see if e.g., couples with white skin are overrepresented. It would also be interesting to analyze the age of the couples, to see if the images are mainly of one specific age group or if an age group is underrepresented."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
